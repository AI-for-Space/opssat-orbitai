## Classification Metrics

The confusion matrices and the follwoing classification metrics are calculed for all trained models:
- Sensitivity
- Specificity
- Precision
- Negative Predictive Value
- Biased Accuracy
- Balanced Accuracy
- F1 Score

These values are calculated by the _analyze.py_ script:
```bash
python3 analyze.py <string:inference_csv_log_file> <string:metrics_results_output_csv_file>
```

### Ground

Models trained on the ground are obtained by feeding batches of training and inference commands to the Mochi Server. These commands are listed in the _generated_A.txt_ file. This file is generated by the _generate.py_ script:
```python
write_commands_from_generated_data("cmds/generated_A.txt", 0.7, 1.3, 0.01, False)
```

 The _benchmark.py_ script is used to start the Mochi server and send it the batches of training and inference commands:
```bash
./benchmark.sh <int:epochs> <float:sleep> <string:commands_filename>
```

The _benchmark.py_ script parameters are:
- epochs: the number of training epochs.
- sleep: sleep time between each commands sent.
- commands_filename: path to the file listing all the commands to send to the Mochi server.

After each training epoch, the _benchmark.py_ script invokes the _analyze.py_ script on the trained models' _inference.csv_ log files. The results of the calculated classification metrics are written as csv files inside the _ground_ folder:
```bash
# Caculate classification metrics of the trained models.
python3 analyze.py logs/inference.csv metrics/ground/epochs_$EPOCH.csv
```

### Space

Models that will be trained on-board the spacecraft, as well as the _inference.csv_ log file, will be downlinked and analyzed with the _analyze.py_ script.